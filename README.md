# ğŸ’¬ ForteBank Chatbot

An intelligent chatbot system for ForteBank that uses NLP techniques (Sentence-BERT embeddings) to understand user queries and return relevant banking service information.

## ğŸš€ Features

- Used Web Scraping technologies (Selenium, BeautifulSoup) to collect data from ForteBank pages about cards, credits, deposits, transfers, salary projects
- Preprocessed and embedded data from ForteBank service descriptions
- Sentence-BERT model to convert user queries into semantic embeddings
- Semantic search using cosine similarity
- Simple web-based interface via FastAPI
- Source links included with each result
- Modular structure for easy maintenance

---

## Web Scraping ForteBank Services 
This project includes a custom web scraper that collects information about banking services offered by ForteBank, including cards, credits, deposits, transfers, and salary projects.

### ğŸ›  Technologies Used 
- Selenium â€“ for browser automation and interacting with dynamic content
- BeautifulSoup â€“ for parsing HTML content
- webdriver_manager â€“ for automatic ChromeDriver management
- csv â€“ for saving data in structured format

### ğŸ“‹ Collected Services 
The scraper collects data about the following services:
-Bank Cards
-Credits (Loans)
-Deposits
-Money Transfers
-Salary Projects

### ğŸ“„ Data Fields 
Each scraped service includes:
-service_name â€“ the category of the service (e.g., "card", "credit")
-name â€“ the title of the individual product
-description â€“ a short summary or explanation
-url â€“ a link to the service details (if available)

### ğŸ“‚ Output File 
The collected data is saved into a single CSV file:

```bash
data/raw/services.csv
```

## ğŸ§¹ Preprocessing and ğŸ§  Tokenization Pipeline

To prepare the scraped data for semantic search or machine learning tasks, this project includes a **preprocessing and tokenization pipeline** consisting of two main stages.

---

## ğŸ§¹ 1. Preprocessing (`preprocess.py`) 

This stage cleans and prepares the raw service descriptions.

#### Key Steps

| Function             | Purpose                                                                 |
|----------------------|-------------------------------------------------------------------------|
| `delete_null_rows()` | Removes rows with missing or `"null"` values in `name` or `description` |
| `clean_text()`       | Cleans unwanted characters (quotes, bullets, line breaks, etc.)         |
| `combine_rows()`     | Merges `service_name`, `name`, and `description` into a `full_text`     |

Output
Cleaned data is saved to:

```bash
data/processed/services_cleaned.csv
```

## ğŸ§  2. Tokenization (tokenize.py)
This stage converts each cleaned text entry into a dense vector embedding using a multilingual SentenceTransformer model.

- tokenize_text(): Encodes each full_text using the cointegrated/LaBSE-en-ru model
- The model supports both English and Russian, ideal for bilingual banking data.

Embeddings are stored as lists of floats in a new column called embedding.

Model Used
```python
SentenceTransformer("cointegrated/LaBSE-en-ru")
```
Output
Tokenized and embedded data is saved to:

```bash
data/processed/services_with_embeddings.csv
```

## ğŸ” ServiceSearch Model Overview

The `ServiceSearch` class performs semantic search over banking services using the multilingual model `cointegrated/LaBSE-en-ru`.

---

### ğŸ§  How It Works

1. **Initialization (`__init__`)**  
   Loads the query, SentenceTransformer model, and preprocessed services with embeddings.

2. **Category Detection (`detect_category`)**  
   Filters services based on category-related keywords in the query (e.g., "ĞºÑ€ĞµĞ´Ğ¸Ñ‚", "Ğ´ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚").

3. **Text Similarity Search (`get_results`)**  
   Encodes the query and compares it to service embeddings using cosine similarity to find the most relevant services.

4. **Response Formatting (`search`)**  
   Returns the top result in a friendly text format with a URL. If no matches are found, returns a fallback message.

---

### âœ… Example

```python
search = ServiceSearch("Ñ…Ğ¾Ñ‡Ñƒ Ğ²ĞºĞ»Ğ°Ğ´ Ğ² Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€Ğ°Ñ…")
print(search.search())
```

## âš™ï¸ Installation

1. **Clone the repo:**
```bash
git clone https://github.com/aarizona23/fortebank_bot.git
cd fortebank_bot
```

2. **Create a virtual environment:**

```bash
python -m venv venv
source venv/bin/activate
```

3. **Install dependencies:**

```bash
pip install -r requirements.txt
```

4. **ğŸ§  Run the App**
```bash
uvicorn api.main:app --reload
```
Then open your browser at: http://127.0.0.1:8000

<img width="1128" alt="image" src="https://github.com/user-attachments/assets/365a9488-7ee1-4337-8367-c5d61acbed7c" />



